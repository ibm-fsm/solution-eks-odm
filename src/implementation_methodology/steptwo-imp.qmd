---
title: "ODM Deployment & Traffic Exposure"
format: html
date: last-modified
---

## Phase 2: ODM Deployment & Traffic Exposure

In this final phase, we deploy the ODM workload. The configuration must bridge the gap between the Kubernetes Service (ClusterIP) and the AWS ALB, ensuring traffic remains encrypted across the boundary.

### 2.1 Configure Helm Repository

Before generating the deployment manifests, add the IBM Helm repository to your local client. This allows Helm to locate the `ibm-odm-prod` chart.

```bash
# 1. Add the IBM Helm Repo
helm repo add ibm-helm https://raw.githubusercontent.com/IBM/charts/master/repo/ibm-helm

# 2. Update to ensure you have the latest chart versions
helm repo update

# 3. Verify the chart is available (Target: 25.1.0 for ODM 9.5.0.1)
helm search repo ibm-odm-prod
```

:::{.callout-tip}
### Reference Documentation
For a complete list of available configuration parameters, default values, and architectural details, refer to the official [IBM ODM Production Helm Chart README](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2FIBM%2Fcharts%2Fblob%2F0763d5e6882e0b4eafbb2af66b14fa1cc2fdb71c%2Frepo%2Fibm-helm%2Fibm-odm-prod.md).
:::

### 2.2 Helm Chart Configuration

To satisfy the strict OPA policies and network requirements, we must construct a specific `values.yaml` file. This file overrides the default "insecure" settings of the chart.

#### Constructing the Values File

Select the configuration that matches your deployment phase.

:::{.panel-tabset}

## Option A: Production / Pilot (Target State)
**Use Case:** Deployment into the EKS Pilot environment.  
**Key Features:** External RDS Database, Image Digests, Strict Security Contexts.

Create a file named `values-prod.yaml`:

[Download `values-prod.yaml`](../../artifacts/odm/values-prod.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/values-prod.yaml"}
```

:::{.callout-important}
### AWS ALB & OPA "TLS" Constraints
Standard OPA policies (`ingress-https-only`) often check if the `spec.tls` list is populated in the Ingress YAML.

**In AWS ALB:** You typically use the `certificate-arn` annotation instead of a Kubernetes Secret, leaving `spec.tls` empty.

**If OPA blocks this configuration:** You may need to create a "dummy" self-signed secret and reference it in `tlsSecretRef` just to satisfy the OPA regex check, even though the ALB ignores it in favor of the ARN.
:::

## Option B: Lab Validation (Internal DB)
**Use Case:** Sandbox testing where an External RDS is not available.  
**Key Features:** Internal PostgreSQL (Accepts known OPA violation for DB only), Image Digests, Self-Signed Ingress.

Create a file named `values-lab.yaml`:

[Download `values-lab.yaml`](../../artifacts/odm/values-lab.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/values-lab.yaml"}
```

:::

### 2.3. Kustomize Workarounds

While ODM v9.5 resolves many security configurations natively, critical gaps remain that cannot be fixed via `values.yaml` alone:  
1.  **Group ID Enforcement:** The Helm chart templates explicitly define `runAsUser` but ignore `runAsGroup` and `supplementalGroups`. This causes the pods to fail the `psp-pods-allowed-user-ranges` policy. We inject these fields (`1001`) into every Deployment.
2.  **Test Job Compliance:** The `odm-test-connection` Job generated by the chart is unconfigurable via `values.yaml`. It lacks Resource Limits, Security Contexts, and Image Digests. We patch this job to add all missing security fields.
3.  **Image Pull Policy (Init Containers):** The OPA policy requires `imagePullPolicy: Always` for *all* containers. The Helm chart defaults Init Containers to `IfNotPresent` with no option to override. We use a **JSON Patch** to forcibly update the pull policy on every container in the manifest.

#### Create Patch Files

Define the following files in your overlay directory. Note that we utilize distinct patch files for each component to ensure explicit targeting and avoid accidental modification of infrastructure components (such as the database).

##### File 1: `security-patch.yaml`
**Target:** Application Deployments (Decision Center, Runner, Console, Runtime).  
**Purpose:** Injects the mandatory Group IDs required by the "Restricted" OPA policy.

[Download `security-patch.yaml`](../../artifacts/odm/security-patch.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/security-patch.yaml"}
```

##### File 2: `job-security-patch.yaml`
**Target:** The Database Connection Test Job.  
**Purpose:** This job is "unconfigurable" in the standard chart. We must patch it to enforce Image Digests, Resource Limits, and strict Security Contexts.

[Download `job-security-patch.yaml`](../../artifacts/odm/job-security-patch.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/job-security-patch.yaml"}
```

##### File 3: `security-patch-dc.yaml`
**Target:** Decision Center Deployment.  
**Purpose:** Injects the mandatory `runAsGroup: 1001` and `supplementalGroups` into the Decision Center pods, as the Helm chart template ignores these values for this component.

[Download `security-patch-dc.yaml`](../../artifacts/odm/security-patch-dc.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/security-patch-dc.yaml"}
```

##### File 4: `security-patch-runner.yaml`
**Target:** Decision Runner Deployment.  
**Purpose:** Injects the mandatory `runAsGroup: 1001` and `supplementalGroups` into the Decision Runner pods to satisfy the "Restricted" OPA policy.

[Download `security-patch-runner.yaml`](../../artifacts/odm/security-patch-runner.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/security-patch-runner.yaml"}
```

##### File 5: `security-patch-console.yaml`
**Target:** Decision Server Console Deployment.  
**Purpose:** Injects the mandatory `runAsGroup: 1001` and `supplementalGroups` into the Rule Execution Server Console pods.

[Download `security-patch-console.yaml`](../../artifacts/odm/security-patch-console.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/security-patch-console.yaml"}
```

##### File 6: `security-patch-runtime.yaml`
**Target:** Decision Server Runtime Deployment.  
**Purpose:** Injects the mandatory `runAsGroup: 1001` and `supplementalGroups` into the Rule Execution Server Runtime pods.

[Download `security-patch-runtime.yaml`](../../artifacts/odm/security-patch-runtime.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/security-patch-runtime.yaml"}
```

##### File 7: `force-pull-policy.yaml`
**Target:** All ODM Deployments and Jobs.  
**Purpose:** A JSON Patch that overrides the `imagePullPolicy` for **all** containers (including Init Containers, which cannot be configured via Helm). This forces the policy to `Always`, satisfying strict image currency requirements.

[Download `force-pull-policy.yaml`](../../artifacts/odm/force-pull-policy.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/force-pull-policy.yaml"}
```

#### Create Kustomization Manifest

Create the `kustomization.yaml` file to link the patches to the generated resources.

**Important:** We use explicit name targeting to ensure we do not accidentally patch the Database Deployment (if running locally) or other infrastructure components.

*Note: The names below assume your Helm Release Name is `odm-lab`. If you use `odm-pilot`, update the names accordingly (e.g., `odm-pilot-odm-decisioncenter`).*

[Download `kustomization.yaml`](../../artifacts/odm/kustomization.yaml){.btn .btn-outline-primary role="button"}

```{.yaml include="../../artifacts/odm/kustomization.yaml"}
```

:::{.callout-tip}
### Lab Workaround: Non-AppArmor Hosts (RHEL/CentOS/Rocky)

If you are running this deployment in a lab environment based on **RHEL, CentOS, or Rocky Linux**, your kernel likely uses **SELinux** instead of AppArmor.

Including the `container.apparmor.security.beta.kubernetes.io` annotations (which are mandatory for the restricted EKS environment) will cause your lab pods to hang in a `Blocked` state with the error: `Cannot enforce AppArmor: AppArmor is not enabled on the host`.

**Action:** Run the following command to strip these annotations from all YAML files in your current directory before applying the configuration:

```bash
sed -i '/container.apparmor.security.beta.kubernetes.io/d' *.yaml
```
:::

### 2.4 Deploying the Workload

Run the build pipeline to generate the patched manifests and apply them to the cluster.

```bash
# 1. Render Helm Template
# (Change values-prod.yaml to values-lab.yaml if needed)
helm template odm-lab ibm-helm/ibm-odm-prod \
  --version 25.1.0 \
  --kube-version 1.28.0 \
  -f values-prod.yaml > odm-raw.yaml

# 2. Apply Patches & Deploy
kubectl -n odm-pilot apply -k .
```

::: {.callout-tip}
### Verification
After deployment, verify that the ALB has successfully registered the targets.
```bash
kubectl get ingress -n odm-pilot
# Look for the ADDRESS field (e.g., k8s-odmpilot-xxxx.us-east-1.elb.amazonaws.com)
```
Navigate to `https://odm.mycompany.com/decisioncenter`. If the page loads securely, End-to-End encryption is functioning correctly.  
Use `odmAdmin` and the password you set in the `values.yaml` to log in (e.g. `odmAdminPassword123!`).
:::